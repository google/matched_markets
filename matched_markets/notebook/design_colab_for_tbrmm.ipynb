{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfbuo9GAOOyg"
      },
      "source": [
        "# Design of an experiment with TBR using Matched Markets\n",
        "\n",
        "Please note that this colab is for TBR Geo experiments only.\n",
        "\n",
        "\n",
        "Using this colab, you can create a geoexperiment design for a client using TBR in combination with Matched Markets. In the following we will use the acronyms TBR for Time Based Regression and MM for Matched Markets. For a general introduction to TBR and MM, please refer to the TBR [paper](https://research.google/pubs/pub45950/), the MM [paper](https://research.google/pubs/pub48983/), and this [introduction](http://www.unofficialgoogledatascience.com/2016/06/estimating-causal-effects-using-geo.html) to geo experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install git+https://github.com/google/matched_markets.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PeLu1eAGuC7B"
      },
      "outputs": [],
      "source": [
        "#@title Load the libraries needed for the design  \n",
        "\n",
        "BAZEL_VERSION = '3.0.0'\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!sudo apt-get install python3-dev python3-setuptools git\n",
        "!git clone https://github.com/google/matched_markets\n",
        "!python3 -m pip install ./matched_markets\n",
        "!pip install colorama\n",
        "!pip install gspread-dataframe\n",
        "\n",
        "\n",
        "\"\"\"Loading the necessary python modules.\"\"\"\n",
        "import altair as alt\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from scipy import stats\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "import gspread\n",
        "import warnings\n",
        "from colorama import Fore, Style\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google import auth as google_auth\n",
        "from google.colab import auth\n",
        "from google.colab import data_table\n",
        "from google.colab import widgets\n",
        "from google.colab import drive\n",
        "from matched_markets.methodology.common_classes import GeoAssignment\n",
        "from matched_markets.methodology import geoeligibility\n",
        "from matched_markets.methodology import tbrmmdata\n",
        "from matched_markets.methodology import tbrmmdesignparameters\n",
        "from matched_markets.methodology import tbrmmdiagnostics\n",
        "from matched_markets.methodology import tbrmatchedmarkets\n",
        "from matched_markets.methodology import tbrmmdesign\n",
        "from matched_markets.methodology import utils\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_PXNPQe2uPEl"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter the trix url for the sheet file containing the Client Sales Data: \n",
        "#@markdown The spreadsheet should contain the mandatory columns:\n",
        "#@markdown * date: date in the format YYYY-MM-DD\n",
        "#@markdown * geo: the number which identifies the geo\n",
        "#@markdown * response: variable on which you want to measure incrementality\n",
        "#@markdown (e.g. sales, transactions)\n",
        "#@markdown * cost: variable used as spend proxy (e.g. ad spend)\n",
        "\n",
        "#@markdown Other columns can be present in the spreadsheet.\n",
        "\n",
        "#@markdown Spreadsheet URL containing the geo level response and spend data\n",
        "client_sales_table = \"add your url here, which should look like https://docs.google.com/spreadsheets/d/???/edit#gid=???\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Leave the following field empty if you don't want to add constraint to the geo_eligibility\n",
        "geo_eligibility_table = \"add your url here, which should look like https://docs.google.com/spreadsheets/d/???/edit#gid=???\" #@param {type:\"string\"}\n",
        "auth.authenticate_user()\n",
        "creds, _ = google_auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "wks = gc.open_by_url(client_sales_table).sheet1\n",
        "data = wks.get_all_values()\n",
        "headers = data.pop(0)\n",
        "geo_level_time_series = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "geo_level_time_series[\"date\"] = pd.to_datetime(geo_level_time_series[\"date\"])\n",
        "for colname in [\"response\", \"geo\", \"cost\"]:\n",
        "  geo_level_time_series[colname] = pd.to_numeric(geo_level_time_series[colname])\n",
        "\n",
        "num_geos = geo_level_time_series[\"geo\"].nunique()\n",
        "\n",
        "if not geo_eligibility_table:\n",
        "  geo_eligibility = None\n",
        "else:\n",
        "  wks = gc.open_by_url(geo_eligibility_table).sheet1\n",
        "  data = wks.get_all_values()\n",
        "  headers = data.pop(0)\n",
        "  geo_eligibility = pd.DataFrame(data, columns=headers)\n",
        "  for colname in [\"geo\", \"control\", \"treatment\", \"exclude\"]:\n",
        "    geo_eligibility[colname] = pd.to_numeric(geo_eligibility[colname])\n",
        "  # set missing geos in geo_eligibility as eligible for any assignment\n",
        "  geo_eligibility = utils.default_geo_assignment(geo_level_time_series,\n",
        "                                                 geo_eligibility)\n",
        "  geo_eligibility = geoeligibility.GeoEligibility(geo_eligibility)\n",
        "  geo_eligibility.data.index = pd.to_numeric(geo_eligibility.data.index,\n",
        "                                             downcast=\"integer\").astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eehzm284OiGo"
      },
      "outputs": [],
      "source": [
        "#@title Select the parameters for the design of the experiment \n",
        "\n",
        "## The minimum detectable iROAS is defined as the value of the true iROAS such\n",
        "## that, given a confidence_level (input) % confidence level for a one-sided\n",
        "## test, gives a power_level (input) % power if the true iROAS is equal to the\n",
        "## minimum detectable iROAS.\n",
        "minimum_detectable_iROAS =  3#@param{type: \"number\"}\n",
        "#@markdown Use an average order value of 1 if the design is based on\n",
        "#@markdown sales/revenue or an actual average order value (e.g. $80) for a\n",
        "#@markdown design based on transactions/footfall/contracts.\n",
        "average_order_value =  1#@param{type: \"number\"}\n",
        "\n",
        "confidence_level = 0.90 #@param {type:\"number\"}\n",
        "power_level = 0.80 #@param {type:\"number\"}\n",
        "experiment_duration_in_weeks = 4 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown List the maximum budget for the experiment e.g. 300000\n",
        "experiment_budget =  300000#@param{type: \"number\"}\n",
        "#@markdown List any alternative budget which you would like to test separated\n",
        "#@markdown by a comma, e.g. 125000, 150000\n",
        "alternative_budget = \"\" #@param{type: \"string\"}\n",
        "additional_budget = [float(re.sub(r\"\\W+\", \"\", x)) for x in\n",
        "                     alternative_budget.split(',') if alternative_budget != \"\"]\n",
        "\n",
        "#@markdown List the days and time periods that you want to exclude separated by\n",
        "#@markdown a comma e.g. 2019/10/10, 2010/10/11, 2018/10/20-2018/11/20.\n",
        "#@markdown The format for time periods is \"YYYY/MM/DD - YYYY/MM/DD\",\n",
        "#@markdown where the two dates specify the start and end date for the period.\n",
        "#@markdown The format for day is \"YYYY/MM/DD\". Leave empty to\n",
        "#@markdown use all days/weeks.\n",
        "day_week_exclude = \"\" #@param {type: \"string\"}\n",
        "day_week_exclude = [] if day_week_exclude == \"\" else [\n",
        "    re.sub(r\"\\s+\", \"\", x) for x in day_week_exclude.split(\",\")\n",
        "]\n",
        "## Find all the days we should exclude from the analysis from the input\n",
        "periods_to_exclude = utils.find_days_to_exclude(day_week_exclude)\n",
        "days_exclude = utils.expand_time_windows(periods_to_exclude)\n",
        "\n",
        "## Additional constraints which will be flagged in red if not met in\n",
        "## the design\n",
        "\n",
        "# upper bound on the minimal detectable relative lift\n",
        "minimum_detectable_lift_in_response_metric = 0.1 * 100\n",
        "# lower bound on the baseline revenue covered by the treatment group\n",
        "minimum_revenue_covered_by_treatment = 0.05 * 100\n",
        "\n",
        "frequency = utils.infer_frequency(geo_level_time_series, 'date', 'geo')\n",
        "if frequency == \"D\":\n",
        "  n_test = experiment_duration_in_weeks * 7\n",
        "  ## Use the most recent ~6 months\n",
        "  n_pretest = 180\n",
        "elif frequency == \"W\":\n",
        "  n_test = experiment_duration_in_weeks\n",
        "  n_pretest = 26\n",
        "\n",
        "## Other constraints/parameters which are hidden to the user\n",
        "\n",
        "## Ratio of avg. control group response / avg. treatment group response must be\n",
        "## between 1/(1+volume_ratio_tolerance) and 1+volume_ratio_tolerance\n",
        "volume_ratio_tolerance = np.inf\n",
        "## Ratio of number of control geos / number treatment geos must be\n",
        "## between 1/(1+geo_ratio_tolerance) and 1+geo_ratio_tolerance\n",
        "geo_ratio_tolerance = np.inf\n",
        "## Constrain on the % of the treatment group response with respect to the\n",
        "## overall response\n",
        "treatment_share_range = (0.0001, 0.9999)\n",
        "## Minimum and maximum number of geos to include in the treatment group\n",
        "treatment_geos_range = (1, num_geos - 1)\n",
        "## Minimum and maximum number of geos to include in the control group\n",
        "control_geos_range = (1, num_geos - 1)\n",
        "## Maximum number of geos to include in the search\n",
        "n_geos_max = num_geos\n",
        "## Maximum number of pretest timepoints to include in the time series for the\n",
        "## purpose of estimating minimum detectable response \n",
        "n_pretest_max = n_pretest\n",
        "## Number of design to store during the exhaustive search\n",
        "n_designs = 3\n",
        "## Maximum assumed treatment-control correlation to use for estimating the MDR\n",
        "rho_max = 0.995\n",
        "## Minimum acceptable Pearson correlation between the treatment and control\n",
        "## time series.\n",
        "min_corr = 0.8\n",
        "## Inverse quantile of the f distribution parameter 'phi' used in the TBR\n",
        "## preanalysis formula.\n",
        "flevel = 0.9\n",
        "\n",
        "budget_range = (0.1, experiment_budget)\n",
        "min_volume_ratio = 1/(1 + volume_ratio_tolerance)\n",
        "max_volume_ratio = 1 + volume_ratio_tolerance\n",
        "\n",
        "tbr_parameters = tbrmmdesignparameters.TBRMMDesignParameters(\n",
        "    n_test=n_test,\n",
        "    iroas=minimum_detectable_iROAS,\n",
        "    volume_ratio_tolerance=volume_ratio_tolerance,\n",
        "    geo_ratio_tolerance=geo_ratio_tolerance,\n",
        "    treatment_share_range=treatment_share_range,\n",
        "    budget_range=budget_range,\n",
        "    treatment_geos_range=treatment_geos_range,\n",
        "    control_geos_range=control_geos_range,\n",
        "    n_geos_max=n_geos_max,\n",
        "    n_pretest_max=n_pretest_max,\n",
        "    n_designs=n_designs,\n",
        "    sig_level=confidence_level,\n",
        "    power_level=power_level,\n",
        "    min_corr=min_corr,\n",
        "    rho_max=rho_max,\n",
        "    flevel=flevel)\n",
        "\n",
        "# remove dates that the user wants to exclude\n",
        "data_for_design = geo_level_time_series[~geo_level_time_series['date']\n",
        "                                        .isin(days_exclude)].copy()\n",
        "tbrclass = tbrmmdata.TBRMMData(df=data_for_design,\n",
        "                               response_column='response',\n",
        "                               geo_eligibility=geo_eligibility)\n",
        "\n",
        "MMclass = tbrmatchedmarkets.TBRMatchedMarkets(data=tbrclass,\n",
        "                                              parameters=tbr_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WZ9EopaibKRM"
      },
      "outputs": [],
      "source": [
        "#@title Summary of the possible designs  \n",
        "\n",
        "max_feasible_number_of_designs = 5 * 10 ** 6\n",
        "\n",
        "if MMclass.count_max_designs() < max_feasible_number_of_designs:\n",
        "  matched_designs = MMclass.exhaustive_search()\n",
        "else:\n",
        "  matched_designs = MMclass.greedy_search()\n",
        "\n",
        "if len(matched_designs) == 0:\n",
        "  raise ValueError(f'{Fore.RED}It wasn\\'t possible to find a design within ' +\n",
        "                   f'the constraint in input or because all the designs, ' +\n",
        "                   f'did not pass one among the AA test, structural break ' +\n",
        "                   f'test, or minimum correlation of 0.8\\n{Style.RESET_ALL}')\n",
        "\n",
        "matched_designs.sort(reverse=True)\n",
        "chosen_design = matched_designs[0]\n",
        "\n",
        "if not chosen_design.score.score.aa_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the A/A test. ' +\n",
        "        f'We do not recommend to use the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "if not chosen_design.score.score.bb_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the Brownian Bridge ' +\n",
        "        f'test. The relationship between treatment/control is ' +\n",
        "        f'not stable over time. We do not recommend to use ' +\n",
        "        f'the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "if not chosen_design.score.score.dw_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the Durbin-Watson ' +\n",
        "        f'test. The residuals are autocorrelated. We do not recommend to use ' +\n",
        "        f'the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "minimum_iroas_aov = minimum_detectable_iROAS / average_order_value\n",
        "minimum_detectable_impact = chosen_design.diag.estimate_required_impact(\n",
        "    chosen_design.diag.corr)\n",
        "\n",
        "optimal_budget = minimum_detectable_impact / minimum_iroas_aov\n",
        "lower_budget = optimal_budget *  0.8\n",
        "upper_budget = optimal_budget * 1.2\n",
        "list_of_budgets = [lower_budget, optimal_budget, upper_budget\n",
        "                  ] + additional_budget\n",
        "\n",
        "first_day = geo_level_time_series[\"date\"].max() - pd.Timedelta(\n",
        "    str(experiment_duration_in_weeks) + \"W\")\n",
        "most_recent_geo_level_time_series = geo_level_time_series[\n",
        "    geo_level_time_series['date'] > first_day]\n",
        "\n",
        "total_response = most_recent_geo_level_time_series[\"response\"].sum()\n",
        "total_spend = most_recent_geo_level_time_series[\"cost\"].sum()\n",
        "chosen_design.treatment_geos = {int(x) for x in chosen_design.treatment_geos}\n",
        "chosen_design.control_geos = {int(x) for x in chosen_design.control_geos}\n",
        "designs = []\n",
        "for budget in list_of_budgets:\n",
        "  baseline = most_recent_geo_level_time_series.loc[\n",
        "      most_recent_geo_level_time_series[\"geo\"].isin(chosen_design.treatment_geos\n",
        "                                                   ), \"response\"].sum()\n",
        "  cost_in_experiment = most_recent_geo_level_time_series.loc[\n",
        "      most_recent_geo_level_time_series[\"geo\"].isin(chosen_design.treatment_geos\n",
        "                                                   ), \"cost\"].sum()\n",
        "  min_detectable_iroas = (\n",
        "      average_order_value * minimum_detectable_impact / budget)\n",
        "  min_detectable_lift = (minimum_detectable_impact * 100 / baseline)\n",
        "  num_treatment_geos = len(chosen_design.treatment_geos)\n",
        "  num_control_geos = len(chosen_design.control_geos)\n",
        "  num_removed_geos = num_geos - num_treatment_geos - num_control_geos\n",
        "  treat_control_removed = (f'{num_treatment_geos}  /  {num_control_geos}  / ' +\n",
        "                           f'{num_removed_geos}')\n",
        "  revenue_covered = 100 * baseline / total_response\n",
        "  proportion_cost_in_experiment = cost_in_experiment / total_spend\n",
        "  national_budget = utils.human_readable_number(\n",
        "      budget / proportion_cost_in_experiment)\n",
        "  designs.append({\n",
        "      \"Budget\": utils.human_readable_number(budget),\n",
        "      \"Minimum detectable iROAS\": f'{min_detectable_iroas:.3}',\n",
        "      \"Minimum detectable lift in response\": f'{min_detectable_lift:.2f} %',\n",
        "      \"Treatment/control/excluded geos\": treat_control_removed,\n",
        "      \"Revenue covered by treatment group\": f'{revenue_covered:.2f} %',\n",
        "      \"Cost/baseline response\": f'{(budget / baseline * 100):.2f} %',\n",
        "      \"Cost if test budget is scaled nationally\": national_budget\n",
        "  })\n",
        "\n",
        "\n",
        "## define function to colorcode rows and cells of the output table\n",
        "def is_optimal_design(row):\n",
        "    \"\"\"Color a row in:\n",
        "    - orange if the minimum detectable iROAS of the corresponding design\n",
        "      is larger than the target\n",
        "    - green if its equal to the target\n",
        "    - beige if it's lower than the target\n",
        "    \"\"\"\n",
        "    if float(row[\"Minimum detectable iROAS\"]) == minimum_detectable_iROAS:\n",
        "          return pd.Series('background-color: lightgreen', row.index)\n",
        "    elif float(row[\"Minimum detectable iROAS\"]) > minimum_detectable_iROAS:\n",
        "          return pd.Series('background-color: orange', row.index)\n",
        "    else:\n",
        "          return pd.Series('background-color: beige', row.index)\n",
        "\n",
        "def flag_warning_lift(val, value):\n",
        "    \"\"\"\n",
        "    Color a cell in red if its value is larger than the value\n",
        "    in input\n",
        "    \"\"\"\n",
        "    color = 'red' if float(val.strip(' %')) > value else 'black'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "def flag_warning_revenue(val, value):\n",
        "    \"\"\"\n",
        "    Color a cell in red if its value is smaller than the value\n",
        "    in input\n",
        "    \"\"\"\n",
        "    color = 'red' if float(val.strip(' %')) < value else 'black'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "\n",
        "## convert the table to a pd.DataFrame and select a subset of columns\n",
        "designs = pd.DataFrame(designs)\n",
        "designs.index.rename(\"Design\", inplace=True)\n",
        "designs = designs[[\"Budget\", \"Minimum detectable iROAS\",\n",
        "                   \"Minimum detectable lift in response\",\n",
        "                   \"Treatment/control/excluded geos\",\n",
        "                   \"Revenue covered by treatment group\",\n",
        "                   \"Cost/baseline response\",\n",
        "                   \"Cost if test budget is scaled nationally\"]]\n",
        "\n",
        "## apply colorcoding to rows and cells of the table\n",
        "designs_table = designs.style.applymap(\n",
        "    flag_warning_lift,\n",
        "    value=minimum_detectable_lift_in_response_metric,\n",
        "    subset=[\"Minimum detectable lift in response\"]).applymap(\n",
        "        flag_warning_revenue,\n",
        "        value=minimum_revenue_covered_by_treatment,\n",
        "        subset=[\"Revenue covered by treatment group\"]).apply(\n",
        "            is_optimal_design, axis=1)\n",
        "\n",
        "designs_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GHh81hAIetrY"
      },
      "outputs": [],
      "source": [
        "#@title Select the design to be used in the experiment  \n",
        "#@markdown Select the design using the number as displayed in the table in\n",
        "#@markdown the cell called \"Summary of the possible designs\".\n",
        "\n",
        "selected_design =   1#@param {type:\"integer\"}\n",
        "\n",
        "if selected_design not in designs.index:\n",
        "  raise ValueError(f'the selected design must be one of {designs.index.to_list()}, got {selected_design}')\n",
        "\n",
        "selected_design = int(selected_design)\n",
        "final_design = designs[designs.index == selected_design]\n",
        "selected_budget = final_design[\"Budget\"].values[0]\n",
        "\n",
        "# these are numerical identifier used to denote the two groups\n",
        "group_treatment = GeoAssignment.TREATMENT\n",
        "group_control = GeoAssignment.CONTROL\n",
        "group_excluded = GeoAssignment.EXCLUDED\n",
        "\n",
        "data_for_design.loc[\"assignment\"] = group_excluded\n",
        "data_for_design.loc[data_for_design[\"geo\"].isin(\n",
        "    chosen_design.control_geos), \"assignment\"] = group_control\n",
        "data_for_design.loc[data_for_design[\"geo\"].isin(\n",
        "    chosen_design.treatment_geos), \"assignment\"] = group_treatment\n",
        "\n",
        "# set basic plot parameters\n",
        "chart_width = 600\n",
        "chart_height = 300\n",
        "axis_title_font_size = 16\n",
        "axis_label_font_size = 14\n",
        "title_font_size = 19\n",
        "\n",
        "plot_dict = {\"Response\": {\"colname\": \"response\", \"format\": \"s\"},\n",
        "             \"Ad Spend\": {\"colname\": \"cost\", \"format\": \"s\"}}\n",
        "tb = widgets.TabBar(list(plot_dict.keys()))\n",
        "for k, v in plot_dict.items():\n",
        "  with tb.output_to(k):\n",
        "    # Set y-axis format\n",
        "    format_value = \".1\" if v[\"format\"] == \"s\" else \".2\"\n",
        "    format_string = format_value + v[\"format\"]\n",
        "\n",
        "    # Set dataframe to use for plotting and define y-variable to plot\n",
        "    plot_df = data_for_design[data_for_design[\"assignment\"].isin(\n",
        "        [group_control,\n",
        "        group_treatment])].groupby([\"date\", \"assignment\"],\n",
        "                                    as_index=False)[[\"response\", \"cost\"]].sum()\n",
        "    plot_df[\"assignment\"] = plot_df[\"assignment\"].map({\n",
        "        group_control: \"Control\",\n",
        "        group_treatment: \"Treatment\"\n",
        "    })\n",
        "    y_string = v[\"colname\"] + \":Q\"\n",
        "\n",
        "    # Define how we select based on where the mouse is.\n",
        "    selection = alt.selection_single(\n",
        "        fields=[\"date\"],\n",
        "        nearest=True,\n",
        "        on=\"mouseover\",\n",
        "        empty=\"none\",\n",
        "        clear=\"mouseout\")\n",
        "    bottom_selection = alt.selection_single(\n",
        "        fields=[\"date\"],\n",
        "        nearest=True,\n",
        "        on=\"mouseover\",\n",
        "        empty=\"none\",\n",
        "        clear=\"mouseout\")\n",
        "\n",
        "    # Brush for selecting a location to zoom into on x-axis.\n",
        "    brush = alt.selection(type=\"interval\", encodings=[\"x\"])\n",
        "\n",
        "    # Base chart -- same for top and bottom\n",
        "    base = alt.Chart(plot_df).mark_line().encode(\n",
        "        x=alt.X(\"date:T\", axis=alt.Axis(title=\"\", format=(\"%b %e\")))\n",
        "    )\n",
        "\n",
        "    # Lines for data\n",
        "    lines = base.mark_line().encode(\n",
        "        y=alt.Y(y_string, axis=alt.Axis(title=\" \", format=(format_string)))\n",
        "    )\n",
        "    bottom_lines = lines.encode(alt.X(\"date:T\", scale=alt.Scale(domain=brush)))\n",
        "\n",
        "    # Vertical rule\n",
        "    rule = base.mark_rule().encode(\n",
        "        opacity=alt.condition(selection, alt.value(0.3), alt.value(0)),\n",
        "        tooltip=[\"date:T\", y_string]\n",
        "    ).add_selection(selection)\n",
        "    bottom_rule = base.mark_rule().encode(\n",
        "        opacity=alt.condition(bottom_selection, alt.value(0.3), alt.value(0)),\n",
        "        tooltip=[\"date:T\", y_string]\n",
        "    ).add_selection(bottom_selection)\n",
        "\n",
        "    # Points to denote where the mouse is.\n",
        "    points = lines.mark_point().transform_filter(selection)\n",
        "    bottom_points = bottom_lines.mark_point().transform_filter(bottom_selection)\n",
        "\n",
        "    lines = lines.mark_line().encode(\n",
        "      color=alt.Color(\"assignment\", title=\" \"))\n",
        "    bottom_lines = bottom_lines.mark_line().encode(\n",
        "      color=alt.Color(\"assignment\", title=\" \"))\n",
        "    base_rule = base.transform_pivot(\n",
        "        \"assignment\", value=v[\"colname\"],\n",
        "        groupby=[\"date\"]).mark_rule().encode(tooltip=[\"date:T\"] + [\n",
        "            alt.Tooltip(c, type=\"quantitative\")\n",
        "            for c in plot_df[\"assignment\"].unique()\n",
        "        ])\n",
        "    rule = base_rule.encode(\n",
        "        opacity=alt.condition(selection, alt.value(0.3), alt.value(0))\n",
        "    ).add_selection(selection)\n",
        "    bottom_rule = base_rule.encode(\n",
        "        opacity=alt.condition(bottom_selection, alt.value(0.3), alt.value(0))\n",
        "    ).add_selection(bottom_selection)\n",
        "\n",
        "    scatter_df = plot_df.pivot(\n",
        "        index=\"date\", values=v[\"colname\"], columns=\"assignment\").reset_index()\n",
        "    base = alt.Chart(scatter_df).mark_circle(size=60).encode(\n",
        "        alt.X(\"Control\"),\n",
        "        alt.Y(\"Treatment\"),\n",
        "        tooltip=[\"date\", \"Control\", \"Treatment\"])\n",
        "    regression_line = base.transform_regression(\n",
        "        \"Control\", \"Treatment\", method=\"linear\").mark_line(color=\"red\")\n",
        "    params = alt.Chart(scatter_df).transform_regression(\n",
        "        'Control', 'Treatment', params=True\n",
        "    ).mark_text(align='left', fontSize = 20).encode(\n",
        "        x=alt.value(60),  # pixels from left\n",
        "        y=alt.value(20),  # pixels from top\n",
        "        text='rSquared:N'\n",
        "    )\n",
        "    string_r2 = alt.Chart({'values':[{'x': 30, 'y': 20}]}).mark_text(\n",
        "      text='R^2 = ', fontSize = 20).encode( x=alt.value(30), y=alt.value(20))\n",
        "\n",
        "    # Compile top chart\n",
        "    top_chart = alt.layer(\n",
        "        lines,\n",
        "        points,\n",
        "        rule\n",
        "    ).add_selection(\n",
        "        brush\n",
        "    ).properties(\n",
        "        width=chart_width,\n",
        "        height=chart_height,\n",
        "        title=k\n",
        "    )\n",
        "\n",
        "    # Compile bottom chart\n",
        "    bottom_chart = alt.layer(\n",
        "        bottom_lines,\n",
        "        bottom_rule,\n",
        "        bottom_points\n",
        "    ).properties(\n",
        "        width=chart_width,\n",
        "        height=chart_height\n",
        "    )\n",
        "\n",
        "    # Compile scatterplot\n",
        "    scatter_plot = alt.layer(base, regression_line, params, string_r2).properties(\n",
        "        width=chart_width, height=chart_width, title=k).interactive()\n",
        "    # Combine charts\n",
        "    final_chart = alt.hconcat(\n",
        "        alt.vconcat(\n",
        "            top_chart,\n",
        "            bottom_chart,\n",
        "        ), scatter_plot).resolve_scale(color='independent')\n",
        "\n",
        "    final_chart.configure_axis(\n",
        "        titleFontSize=axis_title_font_size,\n",
        "        labelFontSize=axis_label_font_size\n",
        "    ).configure_title(\n",
        "        fontSize=title_font_size\n",
        "    ).display()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E4qV94M0xyO3"
      },
      "outputs": [],
      "source": [
        "#@title Summary and Results  \n",
        "\n",
        "\n",
        "print(\"Data in input:\\n\")\n",
        "print(\"-  {} Geos \\n\".format(\n",
        "    len(geo_level_time_series[\"geo\"].unique())))\n",
        "\n",
        "print(\"Output:\\n\")\n",
        "print(\"The output contains two lists of geos: one for treatment\" +\n",
        "      \" and the other for control\\n\")\n",
        "\n",
        "human_baseline = utils.human_readable_number(baseline)\n",
        "cost_baseline = list_of_budgets[selected_design] * 100 / baseline\n",
        "print('-  {} Geos in treatment and {} geos control\\n'.format(\n",
        "    len(chosen_design.treatment_geos), len(chosen_design.control_geos)))\n",
        "print(\"    Baseline store response: ${} for treatment\\n\".format(human_baseline))\n",
        "print('    Cost/baseline = ${} / ${} ~ {:.3}%\\n'.format(selected_budget,\n",
        "                                                        human_baseline,\n",
        "                                                        cost_baseline))\n",
        "\n",
        "print(f'Minimum detectable iROAS = ' +\n",
        "      f'{final_design[\"Minimum detectable iROAS\"].values[0]}')\n",
        "print(f'Minimum detectable lift in % = ' +\n",
        "      f'{final_design[\"Minimum detectable lift in response\"].values[0]}')\n",
        "\n",
        "print(f\"The design has Power {100 * power_level:.3}+% with Type-I error \" +\n",
        "      f\"{100 *(1 - confidence_level):.3}% for testing H0: iROAS=0 vs \" +\n",
        "      f\"H1: iROAS >= {final_design['Minimum detectable iROAS'].values[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UnBtlmv10THH"
      },
      "outputs": [],
      "source": [
        "#@title Report stores for treatment and control separately and write to trix \n",
        "\n",
        "#@markdown ###Insert the name google sheets in which we will save the data.\n",
        "#@markdown The trix contains 4 worksheets, named:\n",
        "#@markdown * \"pretest data\", containing the geo level time series;\n",
        "#@markdown * \"geopairs\", containing the pairs of geos and their assignment.\n",
        "#@markdown * \"treatment geos\", contains the list of geos in the treatment;\n",
        "#@markdown * \"control geos\", contains the geos in the control groups.\n",
        "Client_Name = \"TBRMM_Client_Name\" #@param {type:\"string\"}\n",
        "filename_design = Client_Name + \"_design.csv\" #@param {type:\"string\"}\n",
        "\n",
        "design_data = geo_level_time_series.copy()\n",
        "\n",
        "design_data[\"assignment\"] = \"Excluded\"\n",
        "design_data.loc[design_data[\"geo\"].isin(\n",
        "    chosen_design.control_geos), \"assignment\"] = \"Control\"\n",
        "design_data.loc[design_data[\"geo\"].isin(\n",
        "    chosen_design.treatment_geos), \"assignment\"] = \"Treatment\"\n",
        "\n",
        "design_data[\"removed\"] = False\n",
        "design_data.loc[design_data[\"date\"].isin(days_exclude), \"removed\"] = True\n",
        "\n",
        "tmp_parameters = {\n",
        "    \"minimum_detectable_iROAS\": minimum_detectable_iROAS,\n",
        "    \"average_order_value\": average_order_value,\n",
        "    \"confidence_level\": confidence_level,\n",
        "    \"power_level\": power_level,\n",
        "    \"experiment_duration_in_weeks\": experiment_duration_in_weeks,\n",
        "    \"experiment_budget\": experiment_budget,\n",
        "    \"alternative_budget\": alternative_budget,\n",
        "    \"day_week_exclude\": \", \".join(day_week_exclude),\n",
        "    \"selected_design\": selected_design,\n",
        "}\n",
        "\n",
        "parameters = {\"parameter\": list(tmp_parameters.keys()),\n",
        "              \"value\": list(tmp_parameters.values())}\n",
        "\n",
        "\n",
        "sh = gc.create(filename_design)\n",
        "wid = sh.add_worksheet(\"pretest data\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, design_data)\n",
        "wid = sh.add_worksheet(\"treatment geos\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame({\"geo\": list(chosen_design.treatment_geos)}))\n",
        "wid = sh.add_worksheet(\"control geos\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame({\"geo\": list(chosen_design.control_geos)}))\n",
        "wid = sh.add_worksheet(\"parameters used in the design\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame(parameters))\n",
        "out = sh.del_worksheet(sh.sheet1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRObTJT_YA52"
      },
      "source": [
        "# Appendix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ufG6Clwf4ZuV"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//research/colab/notebook:notebook_backend_py3",
        "kind": "private"
      },
      "name": "Design Colab For TBR using Matched Markets.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1FZKmwYwJq6Pha6jva_ZlXbzkYR-FsUsZ",
          "timestamp": 1599811516392
        },
        {
          "file_id": "12HvShKlSGzigZh_J71uxV8_l_l8JacCW",
          "timestamp": 1595575793650
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
